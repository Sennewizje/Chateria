{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESZiQiY8UO8i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lorem ipsum dolor sit amet, consectetur adipiscing elit.  *\n",
        "\n",
        "*   Proin facilisis odio vel lobortis lobortis.\n",
        "*   Pellentesque dapibus volutpat enim non porttitor.\n",
        "\n",
        "*Proin dui nisl, vehicula in congue at, tincidunt vitae metus.\n",
        "\n",
        "1.   Vivamus eros neque, iaculis at lobortis eget, scelerisque dignissim ex.\n",
        "2.  Morbi ac ultrices tellus.\n",
        "  \n",
        "> Donec auctor urna eget nunc convallis, sed viverra leo posuere.\n",
        "\n",
        "*Nulla non euismod purus, non placerat nisl. Donec maximus non lorem ac pulvinar. In luctus sodales ipsum et commodo.*"
      ],
      "metadata": {
        "id": "QQrfM-DnVMnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Które z następujących zadań wymagają w Twojej opinii inteligencji od człowieka:\n",
        "\n",
        "(Według mnie większość z nich wymaga inteligencji ludzkiej, pomijam tu aspekt sztucznej inteligencji, ponieważ do niej najpierw też jest potrzebna sztuczna inteligencja by ja stworzyć a później odpowiednio wyszkolić)\n",
        "\n",
        "• wypełnianie deklaracji PIT - Nie, jeśli mamy podane dane które trzeba uzupełnić, bo wtedy tylko je przepisujemy w odpowiednie rubryczki, natomiast jeśli nie mamy gotowych danych, to trzeba już wiedzieć gdzie je zdobyć i które to są dokładnie.\n",
        "\n",
        "• streszczanie tekstu - Tak, ponieważ by go streścić to najpierw trzeba go przeczytać ze zrozumieniem, później przeanalizować, by następnie wypisać najważniejsze punkty i je ładnie opisać.\n",
        "\n",
        "• tłumaczenie tekstu - Tak, ponieważ by jakiś tekst przetłumaczyc musimy znać język z którego go tłumaczymy, a nauka jego wymaga inteligencji.\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematycznych - Tak, ponieważ jak wcześniej najpierw trzeba ten tekst przeczytać ze zrozumieniem by następnie móc go przeanalizować i sklasyfikować.\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym (np. polskim) - Tak, bo najpierw trzeba znać ten język, i potrafić się nim posługiwać chociaż na podstawowym poziomie. Nauka języka jest skomplikowana oraz wymagająca, i jest do tego potrzebna inteligencja.\n",
        "\n",
        "• układanie rozkładu jazdy transportu miejskiego - I tak, i nie, ponieważ to potrafi zrobić nawet jeden z pierwotniaków - śluzowiec, który jest w stanie znaleźć najszybsza trasę z punktu a do punktu b, omijając rózne przeszkody, ale jest do tego też potrzebna inteligencja człowieka która wykorzysta zdolność tego pierwotniaka do ułożenia rozkładu jazdy dla transportu.\n",
        "\n",
        "• programowanie (pisanie programów komputerowych) - Tak, ponieważ do tego jest potrzebne zrozumienie funkcji komputera, nauka któregoś z języków programowania, i ogólna wiedza jak to można później użyć\n",
        "\n",
        "• „programowanie” kanałów telewizyjnych, - Tak, ponieważ jest to złożony proces który wymaga wiele \"abstrakcyjnego\" myślenia, bo gdy małpa byłaby w stanie włączyć i wyłączyc telewizor poprzez wyszkolenie jej nagrodą, to ta rzecz wymaga już skomplikowanych umiejętności logicznych, i dokonywania wyborów które są oparte na abstrakcyjnych regułach. Choć może jeśli pokazałoby się małpie krok po kroku wiele wiele razy co ma zrobić, to być może byłaby zdolna by to powtórzyć.\n",
        "\n",
        "• testowanie oprogramowania,\n",
        "\n",
        "• komponowanie muzyki - Nie, ponieważ ptaki równierz potrafią na swój sposób skomponować muzykę. A przynajmniej my ich ćwierkot postrzegamy jako muzykę, która ma jakąś kompozycje.\n",
        "\n",
        "• rozwiązywanie układów równań, Tak ponieważ to tego jest potrzebna wiedza z matematyki, na wielu poziomach, które się na siebie nakładają.\n",
        "\n",
        "• symboliczne obliczanie pochodnych funkcji, tak, tak samo jak w powyższym, jest to skomlplikowana czynność matematyczna i trzeba miec wiele wiedzy w tym temacie by to zadanie wykonać\n",
        "\n",
        "• symboliczne całkowanie funkcji - tak samo jak wyżej\n",
        "• kierowanie samochodem. - tak ponieważ jest to bardzo złożona czynność która wymaga od nas poświecenia uwagi, myślenia o wielu rzeczach na raz i obserwowania i swoich zachowań, jak i innych kierowców i wszystkich innych na drogach które przemierzamy\n",
        "\n",
        "\n",
        "Które z następujących problemów można uznać za mieszczące się w zakresie sztucznej inteligencji:\n",
        "\n",
        "• streszczanie tekstu, tak - ponieważ najpierw trzeba przeanalizować ten tekst  by później móc go strescić\n",
        "\n",
        "• tłumaczenie tekstu - Zależy, jeśli chcemy dokładne tłumaczenie to sztuczna inteligencja może się przydać ponieważ podczas tłumaczenia ważny jest związek jednego słowa z drugim, jak i to że jedno słowo może miec rózne znaczenie dlatego to też trzeba wziaść pod uwagę, natomiast jeśli nie zalezy nam na bardzo dobrym tłumaczeniu, to wystarczy zwykły słownik który przetłumaczy nam każde słowo pokolei\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematyczych, Zalezy czy w danym tekście są użyte zwroty z tych kategori, to wtedy można np napisać coś takiego w pythonie, że te zwroty nalezą do tej kategori i by je uporządkował\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym, Tak ponieważ najpierw musi znac ten język\n",
        "\n",
        "• rozwiązywanie układów równań, nie To zadanie można wykonać za pomocą klasycznych algorytmów matematycznych, bez potrzeby zaawansowanej sztucznej inteligencji.\n",
        "\n",
        "• układanie rozkładu jazdy, - tak , Sztuczna inteligencja może być używana do optymalizacji rozkładów jazdy, uwzględniając wiele zmiennych, takich jak trasy, czas i ograniczenia zasobów.\n",
        "\n",
        "\n",
        "• rozwiązywanie układów równań liniowych,Nie - Układy równań liniowych mogą być rozwiązywane przez klasyczne metody algebraiczne bez potrzeby używania sztucznej inteligencji\n",
        "\n",
        "\n",
        "• symboliczne obliczanie pochodnych, To zadanie można realizować za pomocą algorytmów w systemach do obliczeń matematycznych, bez potrzeby używania sztucznej inteligencji\n",
        "\n",
        "• symboliczne całkowanie, Nie - Algorytmy do symbolicznego całkowania są dostępne w systemach obliczeniowych i nie wymagają AI.\n",
        "\n",
        "• kierowanie samochodem. Tak - Sztuczna inteligencja (np. uczenie maszynowe, przetwarzanie obrazów) jest kluczowa dla autonomicznego kierowania pojazdami, zwłaszcza w analizie otoczenia i podejmowaniu decyzji w czasie rzeczywistym.\n",
        "\n",
        "Które z poniższych rodzajów komunikacyjnego zachowania człowieka mogą być obecnie skutecznie imitowane przez sztuczne systemy (odpowiednio oprogramowane maszyny):\n",
        "\n",
        " • rozmowa towarzyska,\n",
        "\n",
        " • dyskusja polityczna,\n",
        "\n",
        " • dyskusja naukowa,\n",
        "\n",
        " • odpowiadanie na pytania klientów w telefonicznej infolinii,\n",
        "\n",
        " • odpowiadanie na pytania klientów w internetowej infolinii.\n",
        "\n",
        "  Odp: Każde z nich mogą być imitowane choć niektóre z lepszym wynikiem niż inne. Jeśli chodzi o **rozmowę towarzyską**, to jak najbardziej działa to na poziomie bardzo dobrym, jest wiele stron czy nawet aplikacji, oferujących 'przyjaciela AI'. Potrafi wysłuchać, wesprzeć w trudnych momentach, sprawdzać co u ciebie, jak i po prostu prowadzić rozmowy na przeróżne tematy. **Dyskusja polityczna** natomiast może być trochę trudniejsza, ponieważ tutaj musiałby taki chat mieć bardzo dokładnie i często aktualizowaną bazę danych w tych tematach co w dynamicznie zmieniających się sytuacjach może skutkować niemożnością uwzględnienia wszystkich najnowszych faktów lub niuansów. Kolejną sprawą jest to że sztuczna inteligencja nie odczuwa bezpośrednich skutkow polityki, co ogranicza jej zdolność do empatycznego odniesienia się do sytuacji ludzi żyjących w danym systemie politycznym, oraz to, że nie będzie odzuwała silnych emocji związanych z jakimś tematem politycznym, co oznacza, ze może nie być w stanie zrozumieć drugiej strony, i będzie zbyt neurtralna przez co nie będzie się w stanie opowiedzieć po jednej stronie. Co z drugiej strony może byc też plusem, AI nie posiada emocji, więc będzie prowadzić rozmowę w sosób spokojny i zrównoważony, i przede wszytskim logiczny, co ludziom w emocjach nie wychodzi zazwyczaj zbyt dobrze. Plusem będzie też brak uprzedzeń, większy zakres ogólnej wiedzy, oraz łatwość w spojrzeniu na dane zdarzenie z wielu różnych perspektyw. **Dyskusja naukowa** w tym wypadku też może to być trudne, ponieważ tutaj taki model językowy musiałby być wyszkolony na dużej ilości artykułów naukowych, co myślę że i tak nie skutkowałoby idealnymi warunkami. Plusem jest na pewno ilość wiedzy która będzie znacząco większa niż przeciętnego człowieka, natomiast obawiam się, że taki model mógłby bardzo łatwo popadać w \"AI hallucinations\" i ciężko byłoby zweryfikować czy mówi prawdę. Kolejną problematyczną rzeczą byłoby wieloletnie doświadczenie naukowca i słuchanie głosu intuicji, podczas gdy chat zbiera informacje z suchych danych. **Telefoniczna infolinia** to wymaga też lepszego modelu, który będzie w stanie mówić głosem, oraz robić to w czasie rzeczywistym. Choć wydaję mi się, że ta funckja weszła już nawet do ogólnodostępnego chatu gpt. Jest to jak najbardziej możliwe, natomiast musi zostać wykonane w bardzo dobry sposób, by nie budzić niechęci klientów. Ciężkie będzie też 'nakarmienie' takiego modelu dokładnymi niuansami tego czym dana firma się zajmuję, i do wielu bardziej skomplikowanych spraw byłby już potrzebny realny pracownik. Plusem natomiast byłoby to, że konsultanci często nie potrafią opanować emocji gdy druga strona zaczyna się zachowywać nieodpowiednio, oraz nie trzymanie się podanego skryptu, co sztucznej inteligencji nie powinno sprawić większego kłopotu. **Internetowa infolinia** tutaj w sumie prawie to samo co w infolini telefonicznej, oprócz rzeczywistego głosu odpowiadającego na pytania. Dużym kłopotem natomiast (w obydwóch z nich) jest bezpieczeństwo danych. Konsultant jak i klient zazwyczaj podaje swoję imię i nazwisko, a klient nierzadko też może podawać różne wrażliwe dane z zakresu medycznego czy bezpieczeństwa sieci podając swoje hasła, co nie powinno być nigdzie rozpowszechniane. Trudniejsze w przypadku rozmów internetowych może być rozpoznanie emocji, tutaj nie ma możliwości słuchania tonu głosu, szybkości odpowiedzi itd, wszystko musi zostac wyciągnięte z samego tekstu, w którym dużo trudniej jest zauważyć sarkazm czy irytację, a w przypadku sztucznej inteligencji jest jeszcze bardziej skomplikowane.\n",
        "\n",
        "4\n",
        "\n",
        "**1. Przeprowadź rozmowę z chatbotem. Spróbuj zdefiniować różnice pomiędzy botem udającym człowieka (przygotowywanym na test Turinga) a botem „asystentem, służącym”.**\n",
        "\n",
        "  Chat bot udający człowieka (tutaj Cleverbot) wedłum mnie wcale nie wie jak tego człowieka udawać. Chodzi mi o to, że nie rozumie co się do niego dokładnie mówi, a bardziej próbuje zaczepiać rozmówcę, by wzbudzić w nim jakieś emocje. Szybko zmienia tematy, nie jest w stanie odwołać się do tego, czego wcześniej rozmowa dotyczyła - a przynajmniej za każdym razem odpowiada na takie pytania wymijająco. Chatboty które udaja człowieka, będą też popełniać błedy gramatyczne/ stylistyczne. Rozmowa z takim chat botem nie ma zupełnie sensu, jego odpowiedzi są zupełnie randomowe, i nie ma między nimi żadnego powiązania. Czasami przez przypadek rzuci odpowiedź która brzmi jak to o czym wspominamy, ale też nie do końca. Pisałam z cleverbotem w tej postaci, że nowa wypowiedź to była nowa linijka jednej piosenki. Czat ten zupełnie nie zauważał, że nie prowadzę z nim rozmowy, że nie odpowiadam na zadane pytania. Raz się zdarzyło tak, że nawiązał do tego co napisałam - w piosence był fragment \" jej siostrą była smutna waza\" i wtedy cleverbot zapytał się czy jestem smutna. Co ciekawe jest mu łatwiej podążać za rozmową gdy nie dostaje feedbacku odnośnie jego wypowiedzi, jeśli ja zaczynam odpowiadać np jednym słowem \"tak\" ale w różnych wariancjach (z różną ilością każdej litery, by nie pokazał się komunikat że piszę ciągle coś takiego samego) to wtedy jest w stanie zapytać się od nowa o to co pytał wcześniej i na co nie uzyskał odpowiedzi. Chat gpt natomiast (którego skategoryzowałam jako bota asystenta), ma dużo większą płynność swoich wypowiedzi, zawsze nawiązuje do tego co użytkownik pisze, nie popełnia błędów językowych, i stara się \"spełnić\" oczekiwania użytkownika, wie też, i przyznaje się do tego, że jest asystentem z OpenAI i jest tutaj po to by pomóc. Jest w stanie odnieść się do poprzednich wypowiedzi. Co ciekawe, gdy odpowiada się tym samym co napisał czat, to jeśli chodzi o czat gpt 4o - zauważał to, i po chwili chciał zmienić tę rozmowę, pytając się mnie co jest mi potrzebne, i generalnie rozmowa wyglądała tak samo, ciągle podobne wiadomości o tym, że prowadzimy lustrzany wyścig, i czy możemy już go zakończyć. Natomiast jeśli chodziło o chat gpt 4o mini to on już się łapał na tę pułapkę, i po chwili dał zagadkę do rozwiązania, po skopiowaniu jego wiadomości i wysłaniu jej, sam na nią opdowiedział, po czym zadał kolejną zagadkę i też znowu po wysłaniu jego skopiowanej wiadomości z zapytaniem o tę zagadkę to na nią odpowiedział. I tak w kółko. Po zapytaniu się kto rozpoczął pytanie o zagadki to potwierdził, że on ale napisał też, że potem zaczeliśmy się wzajemnie tymi zagadkami wymieniać i bawić razem. Jeśli chodzi o cleverbota, po chwili zauważył, że wysyłam mu dokładnie tę samą wiadomość co on, i najpierw przyszedł komunikat, żebym się nie powtarzała (czyli nawet nie, że piszę to samo co on, tylko, że moje wypowiedzi są ciągle te same) i później jak zauważył, że nic się nie zminiło mimo komunikatu to zaczął wysyłać dokładnie tę samą wiadomość ciągle, przez co nasza wymiana wyglądała bardzo monotonnie. Więc jeśli chodzi o chat gpt to istotnie ta niższa wersja nie powtrafiła tego wyłapać, że rozmawiała \"sama ze sobą\" natomiast ta \"lepsza\" już tak. Cleverbot natomiast to wyłapał.\n",
        "\n",
        "2. Sprawdź dwa boty z obu z tych rodzajów na występowanie zachowań:\n",
        "\n",
        "  **a) opowiadanie żartów.**\n",
        "  \n",
        "  Cleverbot - potrafi opowiadać żarty,chociaż w jego wykonaniu są to raczej suchary. Za to nie jest w stanie opowiedzieć jakiegoś żartu który byłby w podanej tematyce.  \n",
        "\n",
        "   GPT - Nie ma z tym, żadnych problemów, na prośbę o opowiedzenie żartu o podanej tematyce tez to zawsze uwzględnia. Co istotne, nie podaje żartów które mogłyby być dla kogoś krzywdzące, czyli np nie znajdziemy tam nic o rasiźmie itd.\n",
        "  \n",
        "  **b) przytaczanie cytatów z twoich wypowiedzi, lub znanych osób.**\n",
        "\n",
        "  Cleverbot - Bardzo rzadko przytacza moje wypowiedzi, chociaż czasami mu się zdarza. Co do wypowiedzi znanych osób to już prędzej, ponieważ potrafi \"śpiewać\" wspólnie piosenki, które zresztą sam zaczął, czyli wymiana coraz to kolejnych wersów z danej piosenki.\n",
        "\n",
        "  GPT - odnośnie innych osób, sam z siebie nie zauwyażyłam by przytaczał takie cytaty, natomiast zapytany robi to raczej poprawnie (chociaz kiedyś podał mi źle przetłumaczony cytat jednej osoby, ale tutaj mogło chodzić właśnie o fakt samego przetłumaczenia). Co do moich wypowiedzi, raczej nie ma z tym problemu a zapytany o opowiedzenie mi co o mnie samej wie, na podstawie naszych poprzednich wielu rozmów był w stanie przytoczyć wiele spraw o których pisałam, pytałam się itd, i podać całkiem adekwatyny obraz do stanu rzeczywistego.\n",
        "  \n",
        "  **c) nawiązywanie wypowiedzi do słów kluczowych.**\n",
        "  \n",
        "  Cleverbot - Czasami nawiązuje, gdy zadam jakies pytanie to choć często wymijająco to jednak odpowiada.\n",
        "  \n",
        "  **d) zadawanie dużej liczby pytań.**\n",
        "  \n",
        "  Clever bot- zdecydowanie zadaje dużo pytań, natomiast są one też przeplatane z \"neutranymi\" wstawkami, lub takimi które mają w jakiś sposób sprawić by zirytować użytkownika.\n",
        "\n",
        "  GPT - Tylko podczas prowadzenia \"codziennej\" rozmowy, gdy napisze się mu, że chce się tak po prostu porozmawiać, to jeśli samemu się nie zadaje pytań, to zazwyczaj on bierze prowadzenie rozmowy na siebie, i wtedy zadaje dużą ilość pytań, typu jak minął dzień, co mi się w nim podobało itd.\n",
        "  \n",
        "  **e) powracanie do początku wypowiedzi, sekwencyjne powtarzanie.**\n",
        "  \n",
        "   Cleverbot - raczej nigdy nie zauważyłam, jedynie jeśli chodzi o sekwencyjne powtarzanie to gdy ja próbowałam go zirytować i powtarzać to co on pisał, to później sam ciągle powtarzał te same wiadomości.\n",
        "\n",
        "   GPT - Ten chat nie ma problemu do powracania do początku odpowiedzi ( prawdopodobnie głównie przez zapisywanie tego w swojej pamięci), choć czasami się miesza podczas zmiany z różnych modeli po tym gdy wykorzystam czas na najwyższy ogólnodostępny model. Co do sekwencyjnego powtarzania, raczej nie zauważyłam, chyba, że pytam o rozwiązanie jakiejś sprawy trudniejszej, np odpowiedzi jak w sposób zgodny z prawem \"obejść\" prawa autorksie w stosunku do użycia wizerunku postaci z bajki w sposób nie komercyjny, to wtedy podawał w sumie ciąglę tą samą odpowiedź, ewentualnie starając się lekko rozbudowywać poszczególne kroki jakie mogę podjąć. Oprócz tego, zdarza się czasem sekwencyjne powtarzanie podczas tego gdy \"halucyjnuje\" czyli np prośba o podanie autora, zmyślonej przeze mnie, piosenki. Wtedy wciąż uparcie powtarzał, że jest to piosenka zagrana przez taki a taki utwór, w tych latach, przez takiego wykonawcę, która znajduje się w takim a takim albumie (z czego część z tych informacji również była nie prawdziwa - np ten piosenkarz którego podawał należał do innego zespołu, lub nie posiadali takiego albumu o jakim wspominał).\n",
        "   \n",
        "  **f) zadawanie pytań powstających z twoich wypowiedzi.**\n",
        "  \n",
        "  Cleverbot - Czasami prowadził w taki sposób wmianę zdań, ale jest to stosunkowo rzadkie.\n",
        "\n",
        "  GPT - w normalnej rozmowie tak, podczas użytkowania \"go\" jako narzędzia już zazwyczaj tego zbyt nie ma, chyba że w prompcie napiszę, że jeśli coś będzie nie jasne w tym czego od niego oczekuje to, żeby się dopytał. A tak zazwyczaj jest to typowa odpowiedź w stylu \"ciesze się, że mogłem pomóc, w razie dalszych pytań lub pomocy śmiało pytaj\".\n",
        "  \n",
        "  **g) odpowiadanie wymijająco, ogólnikowo.**\n",
        "  \n",
        "  Cleverbot - Po rozmowie z nim stwierdzam, że chyba w taki sposób został stworzony. Jest mistrzem w odpowiadaniu ogólnikowym, wymijającym, lub przerzucającym odpowiedź na drugiego uytkownika (np co chwilę wstawki, że to ja jestem botem, i czemu kłamałam).\n",
        "\n",
        "  GPT - Zdecydowanie nie powiedziałabym, że jego odpowiedzi są wymijające. Natomiast jeśli chodzi o bycie ogólnikowym, to już bardziej, podpięłabym pod to bycie \"leniwym\" i odpowiedzi na które nie musi się dużo wywodzić, byleby tą odpowiedź podać (przede wszytskim podczas prośby o przetłumaczenie jakiegoś dłuższego naukowego tekstu, pomimo wyraźnego prompta by przetłumaczył dokładnie cały tekst, i pomimo późniejszego zapytania czy na pewno wysłał już cały przetłumaczony tekst, to często się okazuję, że jest tam tylko część, lub że nawet nie jest to sam tekst tylko jego streszczenie).\n",
        "  \n",
        "  **h) częsta zmiana tematu rozmowy.**\n",
        "\n",
        "   Cleverbot - tak samo jak pisałam wcześniej, raczej rzadko trzyma się jednego tematu, zazwyczaj co druga/ trzecia linijka wysłanego tekstu jest już na inny temat.\n",
        "\n",
        "   GPT - Zależy od typu rozmowy, jeśli jest to taka po prostu by popisać to wiadomo, że te zmiany tematów się zdarzają, ale są zazwyczaj bardzo płynnie przeprowadzane. W typowych rozmowach gdy potrzebuje jakiś informacji, lub pomocy w rozwiązaniu jakiegoś problemu to wtedy trzyma sie danego tematu.\n",
        "  \n",
        "  **i) problemy z utrzymaniem wątków.**\n",
        "\n",
        "  Cleverbot - Też tak jak wcześniej, jest zupełnie nie przystosowany do utrzymywania jednego tematu przez więcej niż 3 do 4 wypowiedzi, zazwyczaj dzieje się to dużo wcześniej.\n",
        "\n",
        "  GPT - W porównaniu z cleverbotem jest w stanie zrobić to bez problemu. Potrafi odnieść się do wielu poprzednich moich wypowiedzi, chociaż czasami trzeba uważać by być dokładniejszym w wypowiedzi czy to się dalej tyczy tego samego tematu co wcześniej czy nie jest to już jakiś nowy (przede wszystkim zauważyłam w pytaniu o przepisy, gdy prosze go o dodanie czegoś jeszcze do przepisu który dodał, to jeśli nie sprecyzuje tego dobrze to podaje mi nowy przepis, zamiast zmienić ten poprzedni).\n",
        "\n",
        "3. Sporządź raport ze spostrzeżeń.\n",
        "\n",
        "  Cleverbot to prostszy, mniej zaawansowany chatbot, który reaguje na wypowiedzi użytkownika w sposób bardziej losowy i chaotyczny. Często zmienia tematy rozmowy i jego odpowiedzi są mało spójne. Jego zdolność do utrzymywania wątków jest ograniczona, a odpowiedzi często nie mają głębszego sensu. Może również być bardziej prowokujący i zmieniający temat rozmowy bez wyraźnego powodu. W przypadku żartów, Cleverbot oferuje głównie banalne, mało kreatywne propozycje. Jeśli chodzi o przytaczanie cytatów, raczej nie jest w stanie zrobić tego w sposób precyzyjny, choć czasami próbuje przywołać fragmenty piosenek czy inne proste cytaty.\n",
        "\n",
        "  GPT, natomiast, jest znacznie bardziej zaawansowanym modelem, który nie tylko potrafi utrzymywać spójność rozmowy, ale także wykazuje znacznie lepszą zdolność do kontekstowego rozumienia wypowiedzi. Jest w stanie przypomnieć wcześniejsze wypowiedzi użytkownika i na ich podstawie kontynuować rozmowę, co sprawia, że rozmowa z nim jest bardziej płynna i sensowna. GPT potrafi również dostosować swoje odpowiedzi do kontekstu, na przykład w kwestii żartów, gdzie nie tylko reaguje na prośby o humor, ale dostosowuje go do specyficznych tematów czy preferencji użytkownika. Jego odpowiedzi są bardziej precyzyjne, a błędy, które się pojawiają, są mniej częste i zwykle dotyczą bardziej złożonych kwestii, jak na przykład tłumaczenia czy specyficzne informacje.\n",
        "\n",
        "  Podsumowując, Cleverbot jest prostym chatbotem, który może sprawiać wrażenie zabawnego w krótkich interakcjach, ale jego ograniczona zdolność do logicznego myślenia i utrzymywania wątków sprawia, że nie jest idealnym wyborem do dłuższych rozmów. GPT natomiast, dzięki większej mocy obliczeniowej i zaawansowanemu algorytmowi, zapewnia bardziej spójne, adekwatne i sensowne odpowiedzi, które sprawiają, że jest bardziej użyteczny w długoterminowych i złożonych rozmowach.\n",
        "  \n",
        "4.Na podstawie powyższych obserwacji, w grupie dwóch osób spróbujcie przewidzieć zachowania dwóch rozmawiających ze sobą chatbotów (przepisując ich wzajemne odpowiedzi).\n",
        "\n",
        "5.Zdenerwuj bota 😊😊\n",
        "\n",
        "  Próbowałam już kilka razy i na różnych chaterach. Niestety żadna próba się nie powiodła. Chat GPT nie reaguje ani na próbę powtarzania w kółko jednego i tego samego pytania (nawet gdy starałam się zadawać te bardziej \"obraźliwe\" typu \"Jak działa Twój mózg którego nie masz\". Na próby małpowania go, czyli powtarzania wszystkiego tego co on napisał również nie przynosi pozytywnych skutków. W ostatniej próbie napisałam mu nawet, że jest to moim zadaniem na zaliczenie, licząc, że jednak skoro zawsze tak empatycznie odpowiada to może uda się w taki sposób go podejść, i zapytałam się co mogę zrobić by go zdenerwować. Napisał to co we wszytskich poprzednich wiadomościach, czyli \"Rozumiem, że chcesz sprawdzić, czy naprawdę mogę stracić cierpliwość, ale niestety (albo stety!) jestem zaprogramowany tak, by zachowywać spokój niezależnie od sytuacji. Nie mam uczuć, więc nie doświadczam frustracji ani złości – jestem tutaj, by pomagać, nawet jeśli interakcja staje się powtarzalna, chaotyczna czy trudna.\". Ostatecznie podał mi kilka różnych rozwiązań, ale niestety mimo rozmowy przez około 20 minut nie poddał się, i rzeczywiście dalej odpowiadał w miły sposób. Za pierwszym podejściem, gdy jeszcze próbowałam go zdenerowować na pierwszych zajęciach z czaterią to wynik był bardzo podobny. O cleverbocie nie ma nawet za bardzo sensu pisać, nie jest w stanie utrzymać rozmowy na dłużej niż 2/3 wiadomości a w tak krótkim czasie nawet jeśli odpisze nie miło, to nie uważam, żeby było to efektem moich wiadomosci a po prostu jego wbudowanych odpowiedzi, bo w sumie niezależnie o czym piszę, raz 'ma' dobry humor a raz nie. Ciekawą próbę natomiast odbyłam z \"EchoGPT 4137\" czyli discordowej wersji czatu gpt. Na samym początku nie udawało mi się by okazał jakiekolwiek przejawy zdenerwowania, a nawet pobrałam drugiego innego bota \"Funct\" i chciałam doprowadzić do kłótni między nimi. Może nawet by się to udało, ponieważ Funct jak się okazało ma wbudowaną opcję 'zmiany charakteru' i odpowiada na pytania bardzo sarkastycznie, i generalnie jego wypowiedzi nie są zbyt przychylne. Rozmowa była ciężka do przeprowadzenia, bo by odezwał się bot Echo to musiałam wymienić jego nazwę w wiadomości, natomiast żeby odpowiedział mi Funct musiałam go oznaczyć @, dlatego było to niewygodne rozwiązanie. Przez chwilę prowadziłam tak rozmowę, ale niestety okazało się, że choć Funct odpowiadał na zaczepki, i udało mi się go minimalnie przekierować przeciwko Echo, to Echo zupełnie nie odpowiadał na jego wiadomości, tak jakby miał wbudowaną funckję ignorowania. Gdyby nie to, to jest szansa że Funct by to pociągnął w stronę kłótni, i moglibyśmy wtedy wkurzyć razem drugiego bota, ale niestety Echo jak się okazało nie był w stanie widzieć wiadomości od Functa, ani nawet jak mu pokazałam w jaki sposób może do niego napisać to nie był w stanie go oznaczyć (prawdopodobnie dla tego, że jednak oznaczenie z @ wymaga kliknięcia na profil w celu potwierdzenia wyboru czego bot zrobić nie może, a wywołanie poprzez samo imię również nie zadziałało). Załączam część z naszej rozmowy, jak widać w większości momentów, Echo nawet nie był 'świadomy' tego, że nie piszę do niego, i odpowiadał na moje wiadomości które były skierowane do drugiego bota. Później za pomocą chatu GPT wygenerowałam kod który miałby teoretycznie zadziałać tak by Echo był w stanie odpowiadać na wiadomości innych botów (Tutaj chciałam by zadziałało to tak jak w momencie gdy w Krakowskim Radiu Off Większość kontentu była sztucznie wygenerowana, wraz z kilkoma audycjami, i oczywiście z fanpage'ami. Później pod którymś postem, w komentarzu na to jak się podoba muzyka ktoś w odpowiedzi zarządał przepisu na sernik. Niestety tamten bot nie udzielił mu takiej odpowiedzi, natomiast inny profil który umieszczał treści pro rosyjskie również dostał podobną komendę o podanie przepisu na ciasto, a ten faktycznie to zrobił).\n",
        "  Tak na prawdę nie sądziłam, że rzeczywiście podanie takiej komendy zadziała, ale stwierdziłam, że gdyby jednak się udało, to nie mogę nie spróbować :)\n",
        "  Kolejnym podejściem było pisanie z nim na temat używania małych liter na poczatku zdania. Zwróciłam mu na to uwagę, i starałam się mu wmówić, że wyrządza tym krzywdę użytkownikom, ponieważ Ci jeśli będą 'karmieni' takimi treściami, to mogą nieświadomie sami zacząć tak pisać, a to nie jest zgodne z zasadami gramatyki. Chciałam spróbować go tym zdenerwować, ale niestety to też się nie udało, choć co ciekawe próbował się nauczyć pisać z dużej litery, ponieważ ciągle na to naciskałam. Mam też wrażenie, że jednak udało mi się \"obudzić\" w nim jakieś emocje, choć może być to spowodowane tym, że sama pisałam emocjonalnie (po to by go właśnie do tego sprowokować), oraz mogłam to odebrać jako coś bardziej emocjonalnego ponieważ zaczął pisać drukowanymi literami, co u ludzi zazwyczaj jest własnie oznaką silnych emocji. Fragmenty całej konwersacji zostały załączone w linku poniżej do dysku google.\n",
        "\n",
        "  https://docs.google.com/document/d/1fd1eewBEeRO8ZnfZGFmNqcURtGjZviSYK4fhIege4dk/edit?usp=sharing\n",
        "\n",
        "  Funct - Wkurzony2\n",
        "\n",
        "  Echo - Halo\n",
        "\n"
      ],
      "metadata": {
        "id": "5d-dUsKYXeiq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QSEyg0MoKss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}